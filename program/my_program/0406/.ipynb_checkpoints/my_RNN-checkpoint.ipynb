{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b0091da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:39.683511Z",
     "start_time": "2023-04-06T13:38:39.675541Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import torch \n",
    "from torch import nn \n",
    "from d2l import torch as d2l \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b31907af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:39.855049Z",
     "start_time": "2023-04-06T13:38:39.850068Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "T = 1000\n",
    "time = torch.arange(1,T+1,dtype=torch.float32)\n",
    "x = torch.sin(0.01*time) +  torch.normal(0,0.2,(T,))\n",
    "#d2l.plot(time,[x],'time','x',xlim=[1,1000],figsize=(6,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4f6ba",
   "metadata": {},
   "source": [
    "### 读取长序列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66f4eac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:40.207787Z",
     "start_time": "2023-04-06T13:38:40.201019Z"
    }
   },
   "outputs": [],
   "source": [
    "#随机\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X), torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da46c58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:40.618633Z",
     "start_time": "2023-04-06T13:38:40.612641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[-0.9266, -1.0180, -1.0822, -0.9665],\n",
      "        [-0.8191, -1.1557, -1.0488, -0.3649]]) \n",
      "Y: tensor([[-1.0180, -1.0822, -0.9665, -0.8191],\n",
      "        [-1.1557, -1.0488, -0.3649, -0.5461]])\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(35))\n",
    "for X, Y in seq_data_iter_random(list(x), batch_size=2, num_steps=4):\n",
    "    print('X: ', X, '\\nY:', Y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c8dc53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:41.040469Z",
     "start_time": "2023-04-06T13:38:41.033179Z"
    }
   },
   "outputs": [],
   "source": [
    "#顺序\n",
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d6055b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:42.482373Z",
     "start_time": "2023-04-06T13:38:42.476560Z"
    }
   },
   "outputs": [],
   "source": [
    "class SeqDataLoader:  #@save\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = d2l.seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = d2l.seq_data_iter_sequential\n",
    "        self.corpus = x\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5216396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T13:38:43.134743Z",
     "start_time": "2023-04-06T13:38:43.130758Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_x_data(batch_size, num_steps, \n",
    "                           use_random_iter=False):\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter)\n",
    "    return data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31d473e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T06:13:12.116742Z",
     "start_time": "2023-04-07T06:13:12.109765Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[ 0.2494, -0.0927,  0.0875,  0.3065],\n",
      "        [-1.0030, -0.9255, -0.9844, -1.0040]]) \n",
      " y tensor([[-0.0927,  0.0875,  0.3065,  0.3750],\n",
      "        [-0.9255, -0.9844, -1.0040, -0.9156]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\d2l\\torch.py:634: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xs = d2l.tensor(corpus[offset: offset + num_tokens])\n",
      "D:\\Anaconda3\\lib\\site-packages\\d2l\\torch.py:635: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Ys = d2l.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n"
     ]
    }
   ],
   "source": [
    "for X,y in load_x_data(2,4):\n",
    "    print('X',X,'\\n','y',y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de1711cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T06:13:38.153330Z",
     "start_time": "2023-04-07T06:13:38.147351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9b146",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39b52b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T06:11:12.121354Z",
     "start_time": "2023-04-07T06:11:12.115736Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_params(steps,num_hiddens, device):\n",
    "    num_inputs = num_outputs = steps\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    #X:批量大小，时间步长\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c9484b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T09:24:29.537233Z",
     "start_time": "2023-04-07T09:24:29.533865Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8a1e421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T09:25:39.681288Z",
     "start_time": "2023-04-07T09:25:39.675112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.T.reshape((4,2,1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ecf4088f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T09:26:14.504270Z",
     "start_time": "2023-04-07T09:26:14.498262Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小=1)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "59cbfe11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T09:52:01.623614Z",
     "start_time": "2023-04-07T09:52:01.615644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10).reshape((2,5,-1))\n",
    "x = x.reshape(x.shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "00a1fadf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T09:28:03.724571Z",
     "start_time": "2023-04-07T09:28:03.717089Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        #X:批量大小x时间步数\n",
    "#         X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        X = X.T\n",
    "        X.reshape(X.shape,1)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c7b4cd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T06:31:07.703038Z",
     "start_time": "2023-04-07T06:31:07.695065Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2494, -0.0927,  0.0875,  0.3065],\n",
       "        [-1.0030, -0.9255, -0.9844, -1.0040]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "680a413c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T06:35:53.973315Z",
     "start_time": "2023-04-07T06:35:53.967668Z"
    }
   },
   "outputs": [],
   "source": [
    "num_hiddens = 512\n",
    "steps = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e2b61988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T08:57:07.035842Z",
     "start_time": "2023-04-07T08:57:07.023760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 4]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = RNNModelScratch(steps,num_hiddens, d2l.try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "X.shape,Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5bfa7c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T09:11:51.390828Z",
     "start_time": "2023-04-07T09:11:51.370389Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10408\\236720139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10408\\930562306.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, state)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbegin_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10408\\1705089295.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(X, state, params)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# X的形状：(批量大小，时间步数量T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mW_xh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "net([1,2,3,4],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c6518",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f1845d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T06:47:14.956378Z",
     "start_time": "2023-04-07T06:47:14.950397Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35b66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.MSELoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
